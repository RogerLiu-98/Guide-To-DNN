{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# A simple Neural Network implemented by Python"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deep Neural Network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# import needed libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Activation function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # Sigmoid function: f(x) = 1 / (1 + e^(-x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A Neuron"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        # Linear combination\n",
    "        output = inputs @ self.weights + self.bias\n",
    "        return sigmoid(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A Simple Deep Neural Network with only feedforward"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216325609518421\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    A neural network with 1 hidden layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        weights = np.array([0, 1])\n",
    "        bias = 0\n",
    "\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        # Neuron 1 in hidden layer\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        # Neuron 2 in hidden layer\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "\n",
    "        # output layer\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "\n",
    "        return out_o1\n",
    "\n",
    "network = NeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate Fake data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2  -1]\n",
      " [ 25   6]\n",
      " [ 17   4]\n",
      " [-15  -6]]\n",
      "[1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "fake_data = np.array([[-2, -1, 1],\n",
    "                      [25, 6, 0],\n",
    "                      [17, 4, 0],\n",
    "                      [-15, -6, 1]])\n",
    "\n",
    "X = fake_data[:, :-1]\n",
    "Y = fake_data[:, -1]\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loss Function\n",
    "\n",
    "We use MSE to calculate the loss between prediction and ground truth.\n",
    "\n",
    "$MSE=\\frac{1}{N}||y_{true} - y_{pred}||^2=\\frac{1}{N}(y_{true}-y_{pred})^T(y_{true}-y_{pred})$\n",
    "\n",
    "We want to minimize the loss function!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def MSE(y_true, y_pred):\n",
    "    # y_true and y_pred should be the same shape\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "y_true = np.array([1, 0, 0, 1])\n",
    "y_pred = np.array([0, 0, 0, 0])\n",
    "print(MSE(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### BackPropagation\n",
    "\n",
    "We still want to use the Gradient Descent to optimize our loss function, but the problem is,\n",
    "how to calculate the gradient?\n",
    "\n",
    "Consider that we represent the loss of the whole network as:\n",
    "$L(w_1, w_2, w_3, w_4, w_5, w_6, b_1, b_2, b_3)$. While $w_1....w_6$ are weight parameters,\n",
    "$b_1...b_3$ are bias parameters.\n",
    "\n",
    "What we want to calculate is the partial derivative of $L$ respect to $w_1....w_6$\n",
    "\n",
    "We first calculate the derivative of $L$ respect to $w_6$:\n",
    "$\\frac{\\partial L}{\\partial w_6}=\\frac{\\partial L}{\\partial y_{pred}} * \\frac{\\partial y_{pred}}{\\partial w_1}$\n",
    "\n",
    "Since we already know that:\n",
    "$L=MSE=\\frac{1}{N}||y_{true} - y_{pred}||^2=\\frac{1}{N}(y_{true}-y_{pred})^T(y_{true}-y_{pred})$\n",
    "\n",
    "We can easily calculate $\\frac{\\partial L}{\\partial y_{pred}}$:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial y_{pred}}\n",
    "&=\\frac{\\partial (\\frac{1}{N}(y_{true}-y_{pred})^T(y_{true}-y_{pred}))}{\\partial y_{pred}}\\\\\n",
    "&=\\frac{1}{N}\\frac{\\partial ({y_{true}}^Ty_{true}-{y_{true}}^Ty_{pred}-{y_{pred}}^Ty_{true}+{y_{pred}}^T{y_{pred}})}{\\partial y_{pred}}\\\\\n",
    "&=-2(y_{true}-y_{pred})^T\\\\\n",
    "&=-2({y_{true}}^T-{y_{pred}}^T)\n",
    "\\end{align}\n",
    "\n",
    "Now we are going to calculate $\\frac{\\partial y_{pred}}{\\partial w_6}$, $h_1, h_2, o_1$ represent the output of their neuron respectively:\n",
    "\n",
    "$y_{pred}=o_1=f(w_5h_1 + w_6h_2 + b_3)$\n",
    "\n",
    "So we have:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial y_{pred}}{\\partial w_6}&=\\frac{\\partial f(w_5h_1 + w_6h_2 + b_3)}{\\partial w_6}\\\\\n",
    "&=h_2 * f^{'}(w_5h_1 + w_6h_2 + b_3)\n",
    "\\end{align}\n",
    "\n",
    "As we have mentioned before, the function $f$ is our activation function, while at there is sigmoid function.\n",
    "\n",
    "$f(x)=\\frac{1}{1-e^{-x}}$\n",
    "$f^{'}(x)=\\frac{e^x}{(1+e^{-x})^2}=f(x)*(1-f(x))$\n",
    "\n",
    "So that we can calculate the partial derivative:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial y_{pred}}{\\partial w_6}&=h_2*\\frac{e^{w_5h_1 + w_6h_2 + b_3}}{(1+e^{-(w_5h_1 + w_6h_2 + b_3)})^2}\n",
    "\\end{align}\n",
    "\n",
    "So finally we can calculate the derivative of $L$ respect to $w_6$\n",
    "$\\frac{\\partial L}{\\partial w_6}=\\frac{\\partial L}{\\partial y_{pred}}\\frac{\\partial y_{pred}}{\\partial w_6}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train: Using SGD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.057\n",
      "Epoch 10 loss: 0.032\n",
      "Epoch 20 loss: 0.022\n",
      "Epoch 30 loss: 0.016\n",
      "Epoch 40 loss: 0.013\n",
      "Epoch 50 loss: 0.011\n",
      "Epoch 60 loss: 0.009\n",
      "Epoch 70 loss: 0.008\n",
      "Epoch 80 loss: 0.007\n",
      "Epoch 90 loss: 0.006\n",
      "Epoch 100 loss: 0.005\n",
      "Epoch 110 loss: 0.005\n",
      "Epoch 120 loss: 0.004\n",
      "Epoch 130 loss: 0.004\n",
      "Epoch 140 loss: 0.003\n",
      "Epoch 150 loss: 0.003\n",
      "Epoch 160 loss: 0.003\n",
      "Epoch 170 loss: 0.003\n",
      "Epoch 180 loss: 0.002\n",
      "Epoch 190 loss: 0.002\n",
      "Epoch 200 loss: 0.002\n",
      "Epoch 210 loss: 0.002\n",
      "Epoch 220 loss: 0.002\n",
      "Epoch 230 loss: 0.002\n",
      "Epoch 240 loss: 0.002\n",
      "Epoch 250 loss: 0.001\n",
      "Epoch 260 loss: 0.001\n",
      "Epoch 270 loss: 0.001\n",
      "Epoch 280 loss: 0.001\n",
      "Epoch 290 loss: 0.001\n",
      "Epoch 300 loss: 0.001\n",
      "Epoch 310 loss: 0.001\n",
      "Epoch 320 loss: 0.001\n",
      "Epoch 330 loss: 0.001\n",
      "Epoch 340 loss: 0.001\n",
      "Epoch 350 loss: 0.001\n",
      "Epoch 360 loss: 0.001\n",
      "Epoch 370 loss: 0.001\n",
      "Epoch 380 loss: 0.001\n",
      "Epoch 390 loss: 0.001\n",
      "Epoch 400 loss: 0.001\n",
      "Epoch 410 loss: 0.001\n",
      "Epoch 420 loss: 0.001\n",
      "Epoch 430 loss: 0.001\n",
      "Epoch 440 loss: 0.001\n",
      "Epoch 450 loss: 0.001\n",
      "Epoch 460 loss: 0.001\n",
      "Epoch 470 loss: 0.000\n",
      "Epoch 480 loss: 0.000\n",
      "Epoch 490 loss: 0.000\n",
      "Epoch 500 loss: 0.000\n",
      "Epoch 510 loss: 0.000\n",
      "Epoch 520 loss: 0.000\n",
      "Epoch 530 loss: 0.000\n",
      "Epoch 540 loss: 0.000\n",
      "Epoch 550 loss: 0.000\n",
      "Epoch 560 loss: 0.000\n",
      "Epoch 570 loss: 0.000\n",
      "Epoch 580 loss: 0.000\n",
      "Epoch 590 loss: 0.000\n",
      "Epoch 600 loss: 0.000\n",
      "Epoch 610 loss: 0.000\n",
      "Epoch 620 loss: 0.000\n",
      "Epoch 630 loss: 0.000\n",
      "Epoch 640 loss: 0.000\n",
      "Epoch 650 loss: 0.000\n",
      "Epoch 660 loss: 0.000\n",
      "Epoch 670 loss: 0.000\n",
      "Epoch 680 loss: 0.000\n",
      "Epoch 690 loss: 0.000\n",
      "Epoch 700 loss: 0.000\n",
      "Epoch 710 loss: 0.000\n",
      "Epoch 720 loss: 0.000\n",
      "Epoch 730 loss: 0.000\n",
      "Epoch 740 loss: 0.000\n",
      "Epoch 750 loss: 0.000\n",
      "Epoch 760 loss: 0.000\n",
      "Epoch 770 loss: 0.000\n",
      "Epoch 780 loss: 0.000\n",
      "Epoch 790 loss: 0.000\n",
      "Epoch 800 loss: 0.000\n",
      "Epoch 810 loss: 0.000\n",
      "Epoch 820 loss: 0.000\n",
      "Epoch 830 loss: 0.000\n",
      "Epoch 840 loss: 0.000\n",
      "Epoch 850 loss: 0.000\n",
      "Epoch 860 loss: 0.000\n",
      "Epoch 870 loss: 0.000\n",
      "Epoch 880 loss: 0.000\n",
      "Epoch 890 loss: 0.000\n",
      "Epoch 900 loss: 0.000\n",
      "Epoch 910 loss: 0.000\n",
      "Epoch 920 loss: 0.000\n",
      "Epoch 930 loss: 0.000\n",
      "Epoch 940 loss: 0.000\n",
      "Epoch 950 loss: 0.000\n",
      "Epoch 960 loss: 0.000\n",
      "Epoch 970 loss: 0.000\n",
      "Epoch 980 loss: 0.000\n",
      "Epoch 990 loss: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roger/miniconda3/envs/NeuralNetwork/lib/python3.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "def derive_sigmoid(x):\n",
    "    fx = sigmoid(x)\n",
    "    return fx * (1 - fx)  # The derivative of sigmoid function f(x) * (1 - f(x))\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    \"\"\"\n",
    "    The structure of the network is a one hidden layer with two neurons network\n",
    "\n",
    "    DO NOT USE IT IN REAL LIFE PROBLEM!\n",
    "    JUST USE IT TO UNDERSTAND HOW DNN WORKS!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Randomly initialize weights\n",
    "        self.w1 = np.random.normal()\n",
    "        self.w2 = np.random.normal()\n",
    "        self.w3 = np.random.normal()\n",
    "        self.w4 = np.random.normal()\n",
    "        self.w5 = np.random.normal()\n",
    "        self.w6 = np.random.normal()\n",
    "        \n",
    "        # Randomly initialize biases\n",
    "        self.b1 = np.random.normal()\n",
    "        self.b2 = np.random.normal()\n",
    "        self.b3 = np.random.normal()\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        h1 = sigmoid(self.w1 * x[0] + self.w2 * x[1] + self.b1)\n",
    "        h2 = sigmoid(self.w3 * x[0] + self.w4 * x[1] + self.b2)\n",
    "        o1 = sigmoid(self.w5 * h1 + self.w6 * h2 + self.b3)\n",
    "        return h1, h2, o1\n",
    "\n",
    "    def train(self, train_x, train_y):\n",
    "        \"\"\"\n",
    "        :param train_x: a Nx2 numpy array, N is the number of sample\n",
    "        :param train_y: a Nx1 numpy array, N is the number of sample\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        lr = 0.1\n",
    "        epochs = 1000\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for x, y in zip(train_x, train_y):\n",
    "                h1, h2, o1 = self.feedforward(x)\n",
    "\n",
    "                # Calculate derivative\n",
    "                d_L_ypred = -2 * (y - o1)  # partial L / partial y_pred\n",
    "\n",
    "                d_ypred_w6 = h2 * derive_sigmoid(o1)\n",
    "                d_ypred_w5 = h1 * derive_sigmoid(o1)\n",
    "                d_ypred_b3 = derive_sigmoid(o1)\n",
    "                \n",
    "                d_ypred_h1 = self.w5 * derive_sigmoid(o1)\n",
    "                d_ypred_h2 = self.w6 * derive_sigmoid(o1)\n",
    "\n",
    "                d_h1_w1 = x[0] * derive_sigmoid(h1)\n",
    "                d_h1_w2 = x[1] * derive_sigmoid(h1)\n",
    "                d_h1_b1 = derive_sigmoid(h1)\n",
    "\n",
    "                d_h2_w3 = x[0] * derive_sigmoid(h2)\n",
    "                d_h2_w4 = x[1] * derive_sigmoid(h2)\n",
    "                d_h2_b2 = derive_sigmoid(h2)\n",
    "\n",
    "                # Update weights and biases\n",
    "                # Neuron h1\n",
    "                self.w1 -= lr * d_L_ypred * d_ypred_h1 * d_h1_w1\n",
    "                self.w2 -= lr * d_L_ypred * d_ypred_h1 * d_h1_w2\n",
    "                self.b1 -= lr * d_L_ypred * d_ypred_h1 * d_h1_b1\n",
    "\n",
    "                self.w3 -= lr * d_L_ypred * d_ypred_h2 * d_h2_w3\n",
    "                self.w4 -= lr * d_L_ypred * d_ypred_h2 * d_h2_w4\n",
    "                self.b2 -= lr * d_L_ypred * d_ypred_h2 * d_h2_b2\n",
    "\n",
    "                self.w5 -= lr * d_L_ypred * d_ypred_w5\n",
    "                self.w6 -= lr * d_L_ypred * d_ypred_w6\n",
    "                self.b3 -= lr * d_L_ypred * d_ypred_b3\n",
    "\n",
    "            # Calculate the Loss\n",
    "            if epoch % 10 == 0:\n",
    "                y_preds = np.apply_along_axis(self.feedforward, 1, X)[:, -1]\n",
    "                loss = MSE(Y, y_preds)\n",
    "                losses.append(loss)\n",
    "                print(\"Epoch %d loss: %.3f\" % (epoch, loss))\n",
    "        return losses\n",
    "\n",
    "n = OurNeuralNetwork()\n",
    "losses = n.train(X, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot loss curve"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss Curve')\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}